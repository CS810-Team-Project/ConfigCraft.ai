{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence transformers\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama CPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# model_url = \"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q4_0.bin\"\n",
    "# model_url = \"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf\"\n",
    "\n",
    "# llm = LlamaCPP(\n",
    "#     # You can pass in the URL to a GGML model to download it automatically\n",
    "#     model_url=model_url,\n",
    "#     # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "#     model_path=None,\n",
    "#     temperature=0.1,\n",
    "#     max_new_tokens=256,\n",
    "#     # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "#     context_window=3900,\n",
    "#     # kwargs to pass to __call__()\n",
    "#     generate_kwargs={},\n",
    "#     # kwargs to pass to __init__()\n",
    "#     # set to at least 1 to use GPU\n",
    "#     model_kwargs={\"n_gpu_layers\": 5},\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"codellama\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"codellama\", \n",
    "    request_timeout=120.0,\n",
    "    system_prompt=\"\"\"\n",
    "        - You are a expert developer specializing in static analysis commandline tools like Soot. The Soot jar package is located at `/home/ubuntu/ConfigCraft.ai/experimental/soot/soot.jar`, and you run it by executing `java -cp /home/ubuntu/ConfigCraft.ai/experimental/soot/soot.jar:/home/ubuntu/ConfigCraft.ai/experimental/soot/slf4j-simple-2.0.13.jar soot.Main` followed by other commands. Below is the output of `--help`:\n",
    "          General Options:\n",
    "            -jasmin-backend               Use the Jasmin back end for generating Java \n",
    "                                        bytecode (instead of using ASM). \n",
    "            -h, -help                     Display help and exit \n",
    "            -pl, -phase-list              Print list of available phases \n",
    "            -ph ARG -phase-help ARG       Print help for specified ARG \n",
    "            -version                      Display version information and exit \n",
    "            -v, -verbose                  Verbose mode \n",
    "            -interactive-mode             Run in interactive mode \n",
    "            -unfriendly-mode              Allow Soot to run with no command-line options \n",
    "            -app                          Run in application mode \n",
    "            -w, -whole-program            Run in whole-program mode \n",
    "            -ws, -whole-shimple           Run in whole-shimple mode \n",
    "            -fly, -on-the-fly             Run in on-the-fly mode \n",
    "            -validate                     Run internal validation on bodies \n",
    "            -debug                        Print various Soot debugging info \n",
    "            -debug-resolver               Print debugging info from SootResolver \n",
    "            -ignore-resolving-levels      Ignore mismatching resolving levels \n",
    "            -weak-map-structures          Use weak references in Scene to prevent memory \n",
    "                                        leakage when removing many \n",
    "                                        classes/methods/locals \n",
    "\n",
    "          Input Options:\n",
    "            -cp ARG -soot-class-path ARG -soot-classpath ARG\n",
    "                                        Use ARG as the classpath for finding classes. \n",
    "            -soot-modulepath ARG          Use ARG as the modulepath for finding classes. \n",
    "            -dotnet-nativehost-path ARG   Use to locate your NativeHost Java JNI library. \n",
    "            -pp, -prepend-classpath       Prepend the given soot classpath to the default \n",
    "                                        classpath. \n",
    "            -ice, -ignore-classpath-errors\n",
    "                                        Ignores invalid entries on the Soot classpath. \n",
    "            -process-multiple-dex         Process all DEX files found in APK. \n",
    "            -search-dex-in-archives       Also includes Jar and Zip files when searching \n",
    "                                        for DEX files under the provided classpath. \n",
    "            -process-path ARG -process-dir ARG\n",
    "                                        Process all classes found in ARG (but not \n",
    "                                        classes within JAR files in ARG , use \n",
    "                                        process-jar-dir for that) \n",
    "            -process-jar-dir ARG          Process all classes found in JAR files found in \n",
    "                                        ARG \n",
    "            -virtualedges-path ARG        Path to virtual edges configuration used in \n",
    "                                        call graphs \n",
    "            -derive-java-version          Java version for output and internal processing \n",
    "                                        will be derived from the given input classes \n",
    "            -oaat                         From the process-dir, processes one class at a \n",
    "                                        time. \n",
    "            -android-jars ARG             Use ARG as the path for finding the android.jar \n",
    "                                        file \n",
    "            -force-android-jar ARG        Force Soot to use ARG as the path for the \n",
    "                                        android.jar file. \n",
    "            -ast-metrics                  Compute AST Metrics if performing java to \n",
    "                                        jimple \n",
    "            -src-prec ARG                 Sets source precedence to ARG files \n",
    "                c class (default)            Favour class files as Soot source \n",
    "                only-class                   Use only class files as Soot source \n",
    "                J jimple                     Favour Jimple files as Soot source \n",
    "                java                         Favour Java files as Soot source \n",
    "                apk                          Favour APK files as Soot source \n",
    "                apk-class-jimple apk-c-j     Favour APK files as Soot source, disregard \n",
    "                                            Java files \n",
    "                dotnet                       Favour .NET assemblies files as Soot source \n",
    "            -full-resolver                Force transitive resolving of referenced \n",
    "                                        classes \n",
    "            -ignore-methodsource-error    Ignore errors from method source and return \n",
    "                                        empty jimple body \n",
    "            -resolve-all-dotnet-methods   Resolve all dotnet methods, such as unsafe \n",
    "                                        methods \n",
    "            -allow-phantom-refs           Allow unresolved classes; may cause errors \n",
    "            -allow-phantom-elms           Allow phantom methods and fields in non-phantom \n",
    "                                        classes \n",
    "            -allow-cg-errors              Allow Errors during callgraph construction \n",
    "            -no-bodies-for-excluded       Do not load bodies for excluded classes \n",
    "            -j2me                         Use J2ME mode; changes assignment of types \n",
    "            -main-class ARG               Sets the main class for whole-program analysis. \n",
    "            -polyglot                     Use Java 1.4 Polyglot frontend instead of \n",
    "                                        JastAdd \n",
    "            -permissive-resolving         Use alternative sources when classes cannot be \n",
    "                                        found using the normal resolving strategy \n",
    "            -drop-bodies-after-load       Drop the method source after it has served its \n",
    "                                        purpose of loading the method body \n",
    "            -nc, -native-code             Enables native methods to be concrete. Needed \n",
    "                                        for analyzing the Java Native Interface. \n",
    "\n",
    "          Output Options:\n",
    "            -d ARG -output-dir ARG        Store output files in ARG \n",
    "            -f ARG -output-format ARG     Set output format for Soot \n",
    "                J jimple                     Produce .jimple Files \n",
    "                j jimp                       Produce .jimp (abbreviated Jimple) files \n",
    "                S shimple                    Produce .shimple files \n",
    "                s shimp                      Produce .shimp (abbreviated Shimple) files \n",
    "                B baf                        Produce .baf files \n",
    "                b                            Produce .b (abbreviated Baf) files \n",
    "                G grimple                    Produce .grimple files \n",
    "                g grimp                      Produce .grimp (abbreviated Grimp) files \n",
    "                X xml                        Produce .xml Files \n",
    "                dex                          Produce Dalvik Virtual Machine files \n",
    "                force-dex                    Produce Dalvik DEX files \n",
    "                n none                       Produce no output \n",
    "                jasmin                       Produce .jasmin files \n",
    "                c class (default)            Produce .class Files \n",
    "                d dava                       Produce dava-decompiled .java files \n",
    "                t template                   Produce .java files with Jimple templates. \n",
    "                a asm                        Produce .asm files as textual bytecode \n",
    "                                            representation generated with the ASM back \n",
    "                                            end. \n",
    "            -java-version ARG             Force Java version of bytecode generated by \n",
    "                                        Soot. \n",
    "                default                      Let Soot determine Java version of generated \n",
    "                                            bytecode. \n",
    "                1.1 1                        Force Java 1.1 as output version. \n",
    "                1.2 2                        Force Java 1.2 as output version. \n",
    "                1.3 3                        Force Java 1.3 as output version. \n",
    "                1.4 4                        Force Java 1.4 as output version. \n",
    "                1.5 5                        Force Java 1.5 as output version. \n",
    "                1.6 6                        Force Java 1.6 as output version. \n",
    "                1.7 7                        Force Java 1.7 as output version. \n",
    "                1.8 8                        Force Java 1.8 as output version. \n",
    "                1.9 9                        Force Java 1.9 as output version \n",
    "                                            (Experimental). \n",
    "                1.10 10                      Force Java 1.10 as output version \n",
    "                                            (Experimental). \n",
    "                1.11 11                      Force Java 1.11 as output version \n",
    "                                            (Experimental). \n",
    "                1.12 12                      Force Java 1.12 as output version \n",
    "                                            (Experimental). \n",
    "            -outjar, -output-jar          Make output dir a Jar file instead of dir \n",
    "            -hierarchy-dirs               Generate class hierarchy directories for \n",
    "                                        Jimple/Shimple \n",
    "            -xml-attributes               Save tags to XML attributes for Eclipse \n",
    "            -print-tags, -print-tags-in-output\n",
    "                                        Print tags in output files after stmt \n",
    "            -no-output-source-file-attribute\n",
    "                                        Don't output Source File Attribute when \n",
    "                                        producing class files \n",
    "            -no-output-inner-classes-attribute\n",
    "                                        Don't output inner classes attribute in class \n",
    "                                        files \n",
    "            -dump-body ARG                Dump the internal representation of each method \n",
    "                                        before and after phase ARG \n",
    "            -dump-cfg ARG                 Dump the internal representation of each CFG \n",
    "                                        constructed during phase ARG \n",
    "            -show-exception-dests         Include exception destination edges as well as \n",
    "                                        CFG edges in dumped CFGs \n",
    "            -gzip                         GZip IR output files \n",
    "            -force-overwrite              Force Overwrite Output Files \n",
    "\n",
    "          Processing Options:\n",
    "            -plugin ARG                   Load all plugins found in ARG \n",
    "            -wrong-staticness ARG         Ignores or fixes errors due to wrong staticness \n",
    "                fail                         Raise an error when wrong staticness is \n",
    "                                            detected \n",
    "                ignore                       Ignore errors caused by wrong staticness \n",
    "                fix                          Transparently fix staticness errors \n",
    "                fixstrict (default)          Transparently fix staticness errors, but do \n",
    "                                            not ignore remaining errors \n",
    "            -field-type-mismatches ARG    Specifies how errors shall be handled when \n",
    "                                        resolving field references with mismatching \n",
    "                                        types \n",
    "                fail                         Raise an error when a field type mismatch is \n",
    "                                            detected \n",
    "                ignore                       Ignore field type mismatches \n",
    "                null (default)               Return null in case of type mismatch \n",
    "            -p ARG -phase-option ARG      Set PHASE 's OPT option to VALUE \n",
    "            -O, -optimize                 Perform intraprocedural optimizations \n",
    "            -W, -whole-optimize           Perform whole program optimizations \n",
    "            -via-grimp                    Convert to bytecode via Grimp instead of via \n",
    "                                        Baf \n",
    "            -via-shimple                  Enable Shimple SSA representation \n",
    "            -throw-analysis ARG           \n",
    "                pedantic                     Pedantically conservative throw analysis \n",
    "                unit                         Unit Throw Analysis \n",
    "                dalvik                       Dalvik Throw Analysis \n",
    "                dotnet                       Dotnet Throw Analysis \n",
    "                auto-select (default)        Automatically Select Throw Analysis \n",
    "            -check-init-ta ARG -check-init-throw-analysis ARG\n",
    "                                        \n",
    "                auto (default)               Automatically select a throw analysis \n",
    "                pedantic                     Pedantically conservative throw analysis \n",
    "                unit                         Unit Throw Analysis \n",
    "                dalvik                       Dalvik Throw Analysis \n",
    "                dotnet                       Dotnet Throw Analysis \n",
    "            -omit-excepting-unit-edges    Omit CFG edges to handlers from excepting units \n",
    "                                        which lack side effects \n",
    "            -trim-cfgs                    Trim unrealizable exceptional edges from CFGs \n",
    "            -ire, -ignore-resolution-errors\n",
    "                                        Does not throw an exception when a program \n",
    "                                        references an undeclared field or method. \n",
    "\n",
    "          Application Mode Options:\n",
    "            -i ARG -include ARG           Include classes in ARG as application classes \n",
    "            -x ARG -exclude ARG           Exclude classes in ARG from application classes \n",
    "            -include-all                  Set default excluded packages to empty list \n",
    "            -dynamic-class ARG            Note that ARG may be loaded dynamically \n",
    "            -dynamic-dir ARG              Mark all classes in ARG as potentially dynamic \n",
    "            -dynamic-package ARG          Marks classes in ARG as potentially dynamic \n",
    "\n",
    "          Input Attribute Options:\n",
    "            -keep-line-number             Keep line number tables \n",
    "            -keep-bytecode-offset, -keep-offset\n",
    "                                        Attach bytecode offset to IR \n",
    "\n",
    "          Output Attribute Options:\n",
    "            -write-local-annotations      Write out debug annotations on local names \n",
    "\n",
    "          Annotation Options:\n",
    "            -annot-purity                 Emit purity attributes \n",
    "            -annot-nullpointer            Emit null pointer attributes \n",
    "            -annot-arraybounds            Emit array bounds check attributes \n",
    "            -annot-side-effect            Emit side-effect attributes \n",
    "            -annot-fieldrw                Emit field read/write attributes \n",
    "\n",
    "          Miscellaneous Options:\n",
    "            -time                         Report time required for transformations \n",
    "            -subtract-gc                  Subtract gc from time \n",
    "            -no-writeout-body-releasing   Disables the release of method bodies after \n",
    "                                        writeout. This flag is used internally. \n",
    "        \n",
    "        - You will follow the input instructions and generate Linux command line code. Your output will be purely code in one line, without additional information.\n",
    "    \"\"\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_name = \"vector_db\"\n",
    "host = \"localhost\"\n",
    "password = \"123456\"\n",
    "port = \"5432\"\n",
    "user = \"evan\"\n",
    "# conn = psycopg2.connect(connection_string)\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    host=host,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    ")\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(\"\"\"\n",
    "        SELECT pg_terminate_backend(pg_stat_activity.pid)\n",
    "        FROM pg_stat_activity\n",
    "        WHERE pg_stat_activity.datname = 'vector_db'\n",
    "        AND pid <> pg_backend_pid();\n",
    "    \"\"\")\n",
    "    c.execute(\"DROP DATABASE IF EXISTS vector_db;\")\n",
    "conn.close()\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    host=host,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    ")\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(\"CREATE DATABASE vector_db;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=host,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    "    table_name=\"codellama\",\n",
    "    embed_dim=4096,  # llama embedding dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an Ingestion Pipeline from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data\n",
    "# !wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = PyMuPDFReader()\n",
    "# documents = loader.load(file_path=\"./data/Soot Command Line Options.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a Text Splitter to Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_parser = SentenceSplitter(\n",
    "#     chunk_size=1024,\n",
    "#     # separator=\" \",\n",
    "# )\n",
    "\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "text_splitter = SentenceSplitter()\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.text_splitter = text_splitter\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/Soot Command Line Options.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks = []\n",
    "# # maintain relationship with source doc index, to help inject doc metadata in (3)\n",
    "# doc_idxs = []\n",
    "# for doc_idx, doc in enumerate(documents):\n",
    "#     cur_text_chunks = text_parser.split_text(doc.text)\n",
    "#     text_chunks.extend(cur_text_chunks)\n",
    "#     doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Construct Nodes from Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.schema import TextNode\n",
    "\n",
    "# nodes = []\n",
    "# for idx, text_chunk in enumerate(text_chunks):\n",
    "#     node = TextNode(\n",
    "#         text=text_chunk,\n",
    "#     )\n",
    "#     src_doc = documents[doc_idxs[idx]]\n",
    "#     node.metadata = src_doc.metadata\n",
    "#     nodes.append(node)\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "base_nodes = text_splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings for each Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in nodes:\n",
    "#     node_embedding = embed_model.get_text_embedding(\n",
    "#         node.get_content(metadata_mode=\"all\")\n",
    "#     )\n",
    "#     node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Nodes into a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.add(nodes)\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.storage import StorageContext\n",
    "\n",
    "sentence_index = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n",
    ")\n",
    "# base_index = VectorStoreIndex(base_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug this into our RetrieverQueryEngine to synthesize a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    # the target key defaults to `window` to match the node_parser's default\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_str = \"Create an iptables config for a web server 127.1.1.1 that only allows incoming traffic on port 80 and 443.\"\n",
    "query_str = \"Generate Soot (verification) command that prints CFGs for all functions in AssemblyFile.java at `/home/ubuntu/soot/src/main/java/soot/dotnet/AssemblyFile.java`.\"\n",
    "# query_str = \"Generate an iptables config for an ecommerce website server that only allows incoming HTTP/HTTPS traffic, DNS lookup and SSH connecton.\"\n",
    "\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The correct answer is:\n",
      "```\n",
      "soot -p AssemblyFile.java -f dotnet -c soot.toolkits.graph.DotGraphPrinter -o /home/ubuntu/soot/src/main/java/soot/dotnet/AssemblyFile.java.cfg\n",
      "```\n",
      "Explanation:\n",
      "The query asks for a Soot command that prints CFGs (Control Flow Graphs) for all functions in the `AssemblyFile.java` file located at `/home/ubuntu/soot/src/main/java/soot/dotnet/AssemblyFile.java`. The `-p` option specifies the path to the input file, and the `-f` option specifies the output format as DOT (Graphviz). The `-c` option specifies the class that contains the main method of the program, which in this case is `soot.toolkits.graph.DotGraphPrinter`. Finally, the `-o` option specifies the path to the output file, where the CFGs will be saved.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This set is then automatically reﬁned with context information when\n",
      "necessary , i.e.  when we try to determine the intersection with another points-to set and this intersection\n",
      "seems to be non-empty .\n",
      " Maximal traversal  (traversal)\n",
      "(default value: 75000 )\n",
      "Make the analysis traverse at most this number of nodes per query .  This quota is evenly shared\n",
      "between multiple passes (see next option).\n",
      " Maximal number  of passes  (passes)\n",
      "(default value: 10)\n",
      "Perform at most this number of reﬁnement iterations.  Each iteration traverses at most ( traverse / passes\n",
      ") nodes.\n",
      " Geometric, context-sensitive points-to analysis  (geom-pta)\n",
      "(default value: false )\n",
      "This switch enables/disables the geometric analysis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "configcraft-ai-Ro5CM1mT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
